import cv2
import mss
import numpy as np
import time
from ultralytics import YOLO

from PIL import ImageFont, ImageDraw, Image

# 시스템에 설치된 한글 폰트 경로를 지정해야 합니다.
# 윈도우 기본 폰트 경로 예시:
FONT_PATH = "C:/Windows/Fonts/malgun.ttf" # 맑은 고딕
# 다른 경로: "C:/Windows/Fonts/H2GPRM.TTF" (한컴 폰트)
FONT_SIZE = 30 # 폰트 크기

# ==============================================================================
# 1. 전역 변수 및 마우스 이벤트 핸들러 (화면 캡처 영역 설정)
# ==============================================================================

# 캡처할 영역의 좌표를 저장하는 딕셔너리
capture_area = {'top': 0, 'left': 0, 'width': 0, 'height': 0}
is_drawing = False
is_roi_selected = False
temp_frame = None

def select_roi(event, x, y, flags, param):
    global capture_area, is_drawing, is_roi_selected, temp_frame
    
    # 마우스 왼쪽 버튼 클릭: 드래그 시작
    if event == cv2.EVENT_LBUTTONDOWN:
        is_drawing = True
        is_roi_selected = False
        capture_area['left'] = x
        capture_area['top'] = y

    # 마우스 이동 중: 현재 드래그 영역 표시
    elif event == cv2.EVENT_MOUSEMOVE:
        if is_drawing:
            # 실시간으로 드래그 영역을 직사각형으로 표시
            frame_copy = temp_frame.copy()
            cv2.rectangle(frame_copy, (capture_area['left'], capture_area['top']), (x, y), (0, 255, 0), 2)
            cv2.imshow("Select Capture Area", frame_copy)

    # 마우스 왼쪽 버튼 떼기: 드래그 종료 및 영역 확정
    elif event == cv2.EVENT_LBUTTONUP:
        is_drawing = False
        is_roi_selected = True
        
        # 영역 계산 및 보정 (음수/제로 너비/높이 방지)
        x_end = x
        y_end = y
        capture_area['left'] = min(capture_area['left'], x_end)
        capture_area['top'] = min(capture_area['top'], y_end)
        capture_area['width'] = abs(x_end - capture_area['left'])
        capture_area['height'] = abs(y_end - capture_area['top'])
        
        # 최소 크기 보장 (너무 작은 영역 방지)
        if capture_area['width'] < 10 or capture_area['height'] < 10:
             print("영역이 너무 작습니다. 다시 선택해주세요.")
             is_roi_selected = False

def put_korean_text(img, text, pos, font_path, font_size, color=(0, 0, 255)):
    # 폰트 로드
    font = ImageFont.truetype(font_path, font_size)
    # OpenCV 이미지를 PIL 이미지로 변환
    img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(img_pil)
    
    # PIL을 사용하여 텍스트 그리기
    # pos는 (x, y) 좌표, color는 RGB 순서여야 함
    draw.text(pos, text, font=font, fill=(color[2], color[1], color[0])) # BGR -> RGB 변환하여 사용
    
    # PIL 이미지를 OpenCV 이미지로 다시 변환
    return cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)

# ==============================================================================
# 2. 메인 실행 함수
# ==============================================================================

def main():
    global temp_frame, is_roi_selected

    # ------------------ [상수 정의 추가] ------------------
    # COCO 데이터셋 클래스 ID (YOLOv8 기본 사용 시)
    PERSON_CLASS_ID = 0
    KNIFE_CLASS_ID = 43    # COCO: knife
    SCISSORS_CLASS_ID = 44 # COCO: scissors
    BAT_CLASS_ID = 39      # COCO: baseball bat
    FORK_CLASS_ID = 42     # COCO: fork
    WRENCH_CLASS_ID = 57   # COCO: wrench

    # 위험 물건으로 간주할 클래스 ID 목록 (더 많은 클래스를 추가할 수 있습니다)
    DANGER_OBJECT_IDS = [KNIFE_CLASS_ID, SCISSORS_CLASS_ID]

    # YOLOv8 모델 감지 결과를 위한 클래스 이름 딕셔너리
    CLASS_NAMES = {
        0: 'person', 43: 'knife', 44: 'scissors'
    }

    # 감지 결과 시각화에 사용할 색상 (BGR 포맷)
    PERSON_COLOR = (255, 0, 0) # 파란색 (사람)
    DANGER_COLOR = (0, 0, 255) # 빨간색 (위험 물건)
    # ---------------------------------------------------

    # 위험 물건 소지 상태를 추적할 딕셔너리 {track_id: True/False}
    # True이면, 칼이 안 보여도 계속 위험 표시를 유지합니다.
    DANGER_MEMORY = {}

    # YOLOv8 모델 로드 (가벼운 'l' 모델 사용)
    model = YOLO('yolov8x.pt')

    # ------------------ 2D 평면도 설정 ------------------
    map_width, map_height = 500, 500
    floor_map = np.full((map_height, map_width, 3), 255, dtype=np.uint8) # 흰색 배경

    # ------------------ 스크린 영역 선택 ------------------
    print("화면 캡처 영역을 마우스 드래그로 선택해주세요.")
    
    with mss.mss() as sct:
        # 초기 화면 전체 캡처
        sct_img = sct.grab(sct.monitors[0]) # 첫 번째 모니터 전체
        temp_frame = np.array(sct_img)
        temp_frame = cv2.cvtColor(temp_frame, cv2.COLOR_BGRA2BGR)
        
        cv2.namedWindow("Select Capture Area")
        cv2.setMouseCallback("Select Capture Area", select_roi)
        
        # 영역이 선택될 때까지 화면을 표시
        while not is_roi_selected:
            cv2.imshow("Select Capture Area", temp_frame)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                return
        
        cv2.destroyWindow("Select Capture Area")
        print(f"캡처 영역 설정 완료: {capture_area}")

        # ------------------ 실시간 분석 루프 (수정됨) ------------------
        while True:
            start_time = time.time()
            
            # 1. 윈도우 화면 캡처 (설정된 영역)
            sct_img = sct.grab(capture_area)
            frame = np.array(sct_img)
            frame = cv2.cvtColor(frame, cv2.COLOR_BGRA2BGR)
            
            # 2. 객체 감지 (사람 및 위험 물건 인식)
            # 감지할 클래스 ID 목록: 사람(0) + 위험 물건(43, 44)
            target_classes = [PERSON_CLASS_ID] + DANGER_OBJECT_IDS

            #results = model(frame, classes=target_classes, verbose=False, iou=0.03, conf=0.03)
            # 2. 객체 추적 및 감지 (사람 및 위험 물건 인식)

            # tracker='bytetrack.yaml'은 YOLOv8에서 제공하는 추적 알고리즘 중 하나입니다.
            results = model.track(
              frame, 
              classes=target_classes, 
              verbose=False, 
              iou=0.01, 
              conf=0.01,
              persist=True, # 추적을 지속하도록 설정
              tracker='bytetrack.yaml' 
              )

            # 3. 위험 물건 감지 및 시각화 로직
            
            # 평면도를 다시 그리기 위해 초기화
            current_map = floor_map.copy()
            
            # 원본 프레임에 결과 시각화용 프레임 복사
            annotated_frame = frame.copy()
            danger_detected = False # 위험 물건 감지 여부 플래그
            
            if results and len(results[0].boxes) > 0:
                # 감지된 객체 정보 추출
                boxes = results[0].boxes.xyxy.cpu().numpy().astype(int)
                classes = results[0].boxes.cls.cpu().numpy().astype(int)
                # 추적 모드일 경우에만 track_id를 추출합니다.
                if results[0].boxes.id is not None:
                    track_ids = results[0].boxes.id.cpu().numpy().astype(int)
                else:
                   # 추적 ID가 없으면 빈 리스트로 처리 (오류 방지)
                    track_ids = [-1] * len(boxes)
                person_boxes = []
                danger_boxes = []
                
                # 사람과 위험 물건 박스 분리 및 원본 프레임에 기본 시각화
                for box, cls_id, track_id in zip(boxes, classes, track_ids):
                    x1, y1, x2, y2 = box
                    
                    if cls_id == PERSON_CLASS_ID:
                        person_boxes.append((box, track_id)) # 사람 박스에 ID 추가
                        # 사람 박스 그리기 (파란색)
                        cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), PERSON_COLOR, 2)
                    elif cls_id in DANGER_OBJECT_IDS:
                        danger_boxes.append(box)
                        danger_detected = True
                        # 위험 물건 박스 그리기 (빨간색)
                        cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), DANGER_COLOR, 3)
                        label = CLASS_NAMES.get(cls_id, 'Danger')
                        cv2.putText(annotated_frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, DANGER_COLOR, 2)
                
                # 4. **사람과 위험 물건의 관계 분석 (흉기 소지 감지)**
                for p_box, p_track_id in person_boxes:
                   px1, py1, px2, py2 = p_box
                   is_holding_danger_in_this_frame = False # 이번 프레임에서 소지했는지 여부
                    
                   # 1) 이번 프레임에서 소지 여부 확인
                   for d_box in danger_boxes:

                      d_x1 = d_box[0]
                      d_y1 = d_box[1]
                      d_x2 = d_box[2]
                      d_y2 = d_box[3]
                      
                      d_center_x = (d_x1 + d_x2) // 2 
                      d_center_y = (d_y1 + d_y2) // 2
                      if px1 < d_center_x < px2 and py1 < d_center_y < py2:
                          is_holding_danger_in_this_frame = True
                          break
        
                   # 2) 메모리 업데이트 및 최종 위험 상태 결정
                   # A. 이번 프레임에서 소지한 경우 -> 메모리에 영구 저장
                   if is_holding_danger_in_this_frame:
                      DANGER_MEMORY[p_track_id] = True
        
                   # B. 메모리에 기록된 위험 소지자인지 확인 (가장 중요한 부분!)
                   is_highlighted_danger = DANGER_MEMORY.get(p_track_id, False)
                    
                   # 위험 물건을 소지한 사람 시각화 강조
                   center_x = (px1 + px2) // 2
                   center_y = py2 # 바운딩 박스 하단
                    
                   if is_highlighted_danger:
                       # 사람 박스를 빨간색 테두리로 다시 그려 강조
                       cv2.rectangle(annotated_frame, (px1, py1), (px2, py2), DANGER_COLOR, 4)
                       cv2.putText(annotated_frame, "의연이 위협 도구", (px1, py1 - 40), cv2.FONT_HERSHEY_SIMPLEX, 1, DANGER_COLOR, 3)
                       
                       # 2D 평면도에 빨간색 점으로 표시
                       map_x = int(center_x / capture_area['width'] * map_width)
                       map_y = int(center_y / capture_area['height'] * map_height)
                       cv2.circle(current_map, (map_x, map_y), 8, DANGER_COLOR, -1) # 더 큰 빨간 점으로 강조

                   else:
                         #일반 사람 시각화 (2D 맵에 일반 사람 위치 표시)
                       map_x = int(center_x / capture_area['width'] * map_width)
                       map_y = int(center_y / capture_area['height'] * map_height)
                       cv2.circle(current_map, (map_x, map_y), 5, PERSON_COLOR, -1) # 파란색 점
            else:
                # 감지 결과가 없을 경우, 원본 캡처 프레임을 그대로 사용
                annotated_frame = frame.copy()


            # ----------------------------------------------------
            # 5. 결과 화면 표시 및 크기 조정 (수정된 부분)
            # ----------------------------------------------------
            
            # 캡처된 화면의 높이를 가져옵니다.
            target_height = annotated_frame.shape[0]

            # 2D 평면도의 높이를 캡처된 화면의 높이에 맞게 조정 (Resizing)
            # 평면도 너비(map_width=500)는 유지하고 높이만 맞춥니다.
            resized_current_map = cv2.resize(
                current_map, 
                (map_width, target_height), # (너비, 높이) 순서
                interpolation=cv2.INTER_LINEAR
            )
            
            # FPS 계산
            end_time = time.time()
            fps = 1 / (end_time - start_time)
            cv2.putText(annotated_frame, f"FPS: {fps:.2f}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
 
            # 위험 감지 시 경고 문구 추가
            alert_text = "*********의연이가 위험**********" if danger_detected else "의연이 안전"
            text_color = DANGER_COLOR if danger_detected else (255, 255, 255)
            annotated_frame = put_korean_text(
                  annotated_frame, 
                  alert_text, 
                  (10, 60), # y 좌표 조정 (FPS 아래)
                  FONT_PATH, 
                  FONT_SIZE, 
                  color=text_color
             )

            # 두 이미지의 높이가 같아졌으므로 수평 합치기 가능
            combined_display = np.hstack((annotated_frame, resized_current_map))

            cv2.imshow("Crowd Analysis System (Combined)", combined_display)

            # 'q'를 누르면 종료
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

        cv2.destroyAllWindows()

if __name__ == "__main__":
    main()
