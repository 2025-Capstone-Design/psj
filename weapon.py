import cv2
import mss
import numpy as np
import time
from ultralytics import YOLO

from PIL import ImageFont, ImageDraw, Image

# ì‹œìŠ¤í…œì— ì„¤ì¹˜ëœ í•œê¸€ í°íŠ¸ ê²½ë¡œë¥¼ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤.
# ìœˆë„ìš° ê¸°ë³¸ í°íŠ¸ ê²½ë¡œ ì˜ˆì‹œ:
# FONT_PATH = "C:/Windows/Fonts/malgun.ttf" # ë§‘ì€ ê³ ë”•
# Linux í™˜ê²½ì„ ìœ„í•´ ê¸°ë³¸ í°íŠ¸ ê²½ë¡œë¥¼ ì£¼ì„ ì²˜ë¦¬í•˜ê³  ì‚¬ìš©ìì—ê²Œ ì•Œë¦½ë‹ˆë‹¤.
# ì ¯ìŠ¨(Linux) í™˜ê²½ì—ì„œ í°íŠ¸ ë¬¸ì œ ë°œìƒ ì‹œ, 'nanumgothic.ttf' ë“±ìœ¼ë¡œ ë³€ê²½ í•„ìš”
FONT_PATH = "C:/Windows/Fonts/malgun.ttf" # ë§‘ì€ ê³ ë”• (ì‚¬ìš©ì í™˜ê²½ì— ë§ê²Œ ë³€ê²½ í•„ìš”)
FONT_SIZE = 30 # í°íŠ¸ í¬ê¸°

# ==============================================================================
# 1. ì „ì—­ ë³€ìˆ˜ ë° ë§ˆìš°ìŠ¤ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ (í™”ë©´ ìº¡ì²˜ ì˜ì—­ ì„¤ì •)
# ==============================================================================

# ìº¡ì²˜í•  ì˜ì—­ì˜ ì¢Œí‘œë¥¼ ì €ì¥í•˜ëŠ” ë”•ì…”ë„ˆë¦¬
capture_area = {'top': 0, 'left': 0, 'width': 0, 'height': 0}
is_drawing = False
is_roi_selected = False
temp_frame = None

def select_roi(event, x, y, flags, param):
    global capture_area, is_drawing, is_roi_selected, temp_frame
    
    # ë§ˆìš°ìŠ¤ ì™¼ìª½ ë²„íŠ¼ í´ë¦­: ë“œë˜ê·¸ ì‹œì‘
    if event == cv2.EVENT_LBUTTONDOWN:
        is_drawing = True
        is_roi_selected = False
        capture_area['left'] = x
        capture_area['top'] = y

    # ë§ˆìš°ìŠ¤ ì´ë™ ì¤‘: í˜„ì¬ ë“œë˜ê·¸ ì˜ì—­ í‘œì‹œ
    elif event == cv2.EVENT_MOUSEMOVE:
        if is_drawing:
            # ì‹¤ì‹œê°„ìœ¼ë¡œ ë“œë˜ê·¸ ì˜ì—­ì„ ì§ì‚¬ê°í˜•ìœ¼ë¡œ í‘œì‹œ
            frame_copy = temp_frame.copy()
            cv2.rectangle(frame_copy, (capture_area['left'], capture_area['top']), (x, y), (0, 255, 0), 2)
            cv2.imshow("Select Capture Area", frame_copy)

    # ë§ˆìš°ìŠ¤ ì™¼ìª½ ë²„íŠ¼ ë–¼ê¸°: ë“œë˜ê·¸ ì¢…ë£Œ ë° ì˜ì—­ í™•ì •
    elif event == cv2.EVENT_LBUTTONUP:
        is_drawing = False
        is_roi_selected = True
        
        # ì˜ì—­ ê³„ì‚° ë° ë³´ì • (ìŒìˆ˜/ì œë¡œ ë„ˆë¹„/ë†’ì´ ë°©ì§€)
        x_end = x
        y_end = y
        capture_area['left'] = min(capture_area['left'], x_end)
        capture_area['top'] = min(capture_area['top'], y_end)
        capture_area['width'] = abs(x_end - capture_area['left'])
        capture_area['height'] = abs(y_end - capture_area['top'])
        
        # ìµœì†Œ í¬ê¸° ë³´ì¥ (ë„ˆë¬´ ì‘ì€ ì˜ì—­ ë°©ì§€)
        if capture_area['width'] < 10 or capture_area['height'] < 10:
             print("ì˜ì—­ì´ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì„ íƒí•´ì£¼ì„¸ìš”.")
             is_roi_selected = False

def put_korean_text(img, text, pos, font_path, font_size, color=(0, 0, 255)):
    # í°íŠ¸ ë¡œë“œ
    try:
        font = ImageFont.truetype(font_path, font_size)
    except IOError:
        print(f"ê²½ê³ : í•œê¸€ í°íŠ¸ íŒŒì¼({font_path})ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ í°íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        # í°íŠ¸ë¥¼ ì°¾ì§€ ëª»í•  ê²½ìš° ê¸°ë³¸ í°íŠ¸ë¥¼ ì‚¬ìš©
        font = ImageFont.load_default() 
        font_size = 20 # ê¸°ë³¸ í°íŠ¸ í¬ê¸° ì¡°ì •
        
    # OpenCV ì´ë¯¸ì§€ë¥¼ PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
    img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(img_pil)
    
    # PILì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
    # posëŠ” (x, y) ì¢Œí‘œ, colorëŠ” RGB ìˆœì„œì—¬ì•¼ í•¨
    # (cv2.COLOR_BGR2RGB ë³€í™˜ í›„ ë‹¤ì‹œ BGRë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì—ì„œ ë°œìƒ)
    draw.text(pos, text, font=font, fill=(color[2], color[1], color[0])) # BGR -> RGB ë³€í™˜í•˜ì—¬ ì‚¬ìš©
    
    # PIL ì´ë¯¸ì§€ë¥¼ OpenCV ì´ë¯¸ì§€ë¡œ ë‹¤ì‹œ ë³€í™˜
    return cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)

# ==============================================================================
# 2. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# ==============================================================================

def main():
    global temp_frame, is_roi_selected

    # ------------------ [ìƒìˆ˜ ì •ì˜] ------------------
    PERSON_CLASS_ID = 0
    KNIFE_CLASS_ID = 43      # COCO: knife
    SCISSORS_CLASS_ID = 44   # COCO: scissors
    DANGER_OBJECT_IDS = [KNIFE_CLASS_ID, SCISSORS_CLASS_ID]
    # ê°ì§€ ëŒ€ìƒ í´ë˜ìŠ¤ (ì‚¬ëŒ, ì¹¼, ê°€ìœ„)
    TARGET_CLASSES = [PERSON_CLASS_ID] + DANGER_OBJECT_IDS

    # ê°ì§€ ê²°ê³¼ ì‹œê°í™”ì— ì‚¬ìš©í•  ìƒ‰ìƒ (BGR í¬ë§·)
    PERSON_COLOR = (255, 0, 0) # íŒŒë€ìƒ‰ (ì‚¬ëŒ)
    DANGER_COLOR = (0, 0, 255) # ë¹¨ê°„ìƒ‰ (ìœ„í—˜ ë¬¼ê±´)
    
    # í‰ê¸° ê°ì§€ ì§€ì† í”„ë ˆì„ ìˆ˜ (ì•½ 1.5ì´ˆ ìœ ì§€)
    DANGER_HOLD_FRAMES = 45 
    
    # YOLOv8 ì¶”ì  ë©”ëª¨ë¦¬: {track_id: ë‚¨ì€_ìœ„í—˜_í”„ë ˆì„_ìˆ˜}
    DANGER_MEMORY = {}

    # YOLOv8 ëª¨ë¸ ë¡œë“œ
    
    # [â­ ì ¯ìŠ¨ ì˜¤ë¦° ë‚˜ë…¸ ìµœì í™” ì„¤ì • ì™„ë£Œ â­]
    # ì´ ì½”ë“œëŠ” TensorRT ì—”ì§„ íŒŒì¼ì— ìµœì í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
    # 1. yolov8x.pt ëª¨ë¸ì„ yolov8x.engine íŒŒì¼ë¡œ ë³€í™˜í•˜ì„¸ìš”.
    # 2. ì´ ì½”ë“œë¥¼ ì ¯ìŠ¨ì—ì„œ ì‹¤í–‰í•˜ë©´ ì´ˆê³ ì† ì‹¤ì‹œê°„ ê°ì§€ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.
    model_path = 'yolov8x.engine' # ğŸš€ ì ¯ìŠ¨ ì˜¤ë¦° ë‚˜ë…¸ ìµœì í™” íŒŒì¼
    # model_path = 'yolov8x.pt'       # PC í™˜ê²½ì—ì„œ ë‹¤ì‹œ í…ŒìŠ¤íŠ¸í•˜ë ¤ë©´ ì´ ì¤„ì˜ ì£¼ì„ì„ í•´ì œí•˜ì„¸ìš”.
    
    try:
        model = YOLO(model_path) 
    except Exception as e:
        print(f"ì˜¤ë¥˜: ëª¨ë¸ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨. íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•˜ê±°ë‚˜ ë³€í™˜ì„ ìˆ˜í–‰í•˜ì„¸ìš”. ({model_path})")
        print(f"ì—ëŸ¬ ë©”ì‹œì§€: {e}")
        return
    
    # ëª¨ë¸ ë¡œë“œ í›„ í´ë˜ìŠ¤ ì´ë¦„ ë”•ì…”ë„ˆë¦¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    CLASS_NAMES = model.names 

    # ------------------ 2D í‰ë©´ë„ ì„¤ì • ------------------
    map_width, map_height = 500, 500
    floor_map = np.full((map_height, map_width, 3), 255, dtype=np.uint8) # í°ìƒ‰ ë°°ê²½

    # ------------------ ìŠ¤í¬ë¦° ì˜ì—­ ì„ íƒ ------------------
    # ì ¯ìŠ¨ í™˜ê²½ì—ì„œëŠ” mss ëŒ€ì‹  ì¹´ë©”ë¼ ì…ë ¥ì„ ì‚¬ìš©í•  ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.
    # ì´ ì½”ë“œëŠ” ë°ìŠ¤í¬í†± í™”ë©´ ìº¡ì²˜(mss)ë¥¼ ì‚¬ìš©í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìœ¼ë¯€ë¡œ, 
    # ì ¯ìŠ¨ì—ì„œ ì›¹ìº  ì…ë ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ ì´ ë¶€ë¶„ì„ cv2.VideoCapture(0) ë“±ìœ¼ë¡œ ë³€ê²½í•´ì•¼ í•©ë‹ˆë‹¤.
    print("í™”ë©´ ìº¡ì²˜ ì˜ì—­ì„ ë§ˆìš°ìŠ¤ ë“œë˜ê·¸ë¡œ ì„ íƒí•´ì£¼ì„¸ìš”. 'q'ë¥¼ ëˆ„ë¥´ë©´ ì¢…ë£Œë©ë‹ˆë‹¤.")
    
    try:
        with mss.mss() as sct:
            # ì´ˆê¸° í™”ë©´ ì „ì²´ ìº¡ì²˜
            sct_img = sct.grab(sct.monitors[0]) # ì²« ë²ˆì§¸ ëª¨ë‹ˆí„° ì „ì²´
            temp_frame = np.array(sct_img)
            temp_frame = cv2.cvtColor(temp_frame, cv2.COLOR_BGRA2BGR)
            
            cv2.namedWindow("Select Capture Area")
            cv2.setMouseCallback("Select Capture Area", select_roi)
            
            # ì˜ì—­ì´ ì„ íƒë  ë•Œê¹Œì§€ í™”ë©´ì„ í‘œì‹œ
            while not is_roi_selected:
                cv2.imshow("Select Capture Area", temp_frame)
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    return
            
            cv2.destroyWindow("Select Capture Area")
            print(f"ìº¡ì²˜ ì˜ì—­ ì„¤ì • ì™„ë£Œ: {capture_area}")

            # ------------------ ì‹¤ì‹œê°„ ë¶„ì„ ë£¨í”„ ------------------
            print("\n--- ì‹¤ì‹œê°„ ë¶„ì„ ëª¨ë“œ ì‹œì‘: í‰ê¸° ê°ì§€ ë¡œì§ í™œì„±í™” (conf=0.20) ---")
            while True:
                start_time = time.time()
                
                # 1. ìœˆë„ìš° í™”ë©´ ìº¡ì²˜ (ì„¤ì •ëœ ì˜ì—­)
                sct_img = sct.grab(capture_area)
                frame = np.array(sct_img)
                frame = cv2.cvtColor(frame, cv2.COLOR_BGRA2BGR)
                
                # 2. ê°ì²´ ì¶”ì  ë° ê°ì§€ (ì‚¬ëŒ, ì¹¼, ê°€ìœ„ë§Œ ê°ì§€í•˜ë©°, í‰ê¸° ê°ì§€ ë¯¼ê°ë„ ì¡°ì •)
                results = model.track(
                    frame, 
                    classes=TARGET_CLASSES, # ì‚¬ëŒ, ì¹¼, ê°€ìœ„ë§Œ ê°ì§€
                    verbose=False, 
                    iou=0.30, 
                    conf=0.20, # í‰ê¸° ê°ì§€ ë¯¼ê°ë„ (ì‹¤í—˜ì  ê°’)
                    persist=True, 
                    tracker='bytetrack.yaml' 
                    )

                # 3. ìœ„í—˜ ë¬¼ê±´ ê°ì§€ ë° ì‹œê°í™” ë¡œì§
                current_map = floor_map.copy()
                annotated_frame = frame.copy()
                
                # ì´ë²ˆ í”„ë ˆì„ì—ì„œ ìœ„í—˜ ë¬¼ê±´ì„ ì†Œì§€í•œ ê²ƒìœ¼ë¡œ íŒë‹¨ëœ ì‚¬ëŒì˜ íŠ¸ë™ ID ì§‘í•©
                current_danger_track_ids = set() 
                
                if results and len(results[0].boxes) > 0:
                    boxes_tensor = results[0].boxes
                    boxes = boxes_tensor.xyxy.cpu().numpy().astype(int)
                    classes = boxes_tensor.cls.cpu().numpy().astype(int)
                    conf_scores = boxes_tensor.conf.cpu().numpy()
                    track_ids = boxes_tensor.id.cpu().numpy().astype(int) if boxes_tensor.id is not None else [-1] * len(boxes)
                    
                    person_data = [] # (box, track_id, center_x, center_y, size)
                    danger_data = []  # (box, center_x, center_y, conf_score)
                    
                    # ê°ì²´ ë¶„ë¥˜ ë° ë°ì´í„° ì¤€ë¹„
                    for box, cls_id, conf, track_id in zip(boxes, classes, conf_scores, track_ids):
                        x1, y1, x2, y2 = box
                        center_x = (x1 + x2) // 2
                        center_y = (y1 + y2) // 2
                        
                        if cls_id == PERSON_CLASS_ID:
                            # ì‚¬ëŒ ë°ì´í„° ìˆ˜ì§‘ (í¬ê¸° ê³„ì‚° í¬í•¨)
                            width = x2 - x1
                            height = y2 - y1
                            avg_size = (width + height) / 2
                            person_data.append((box, track_id, center_x, center_y, avg_size))
                            # ì‚¬ëŒ ë°•ìŠ¤ ê·¸ë¦¬ê¸° (ê¸°ë³¸: íŒŒë€ìƒ‰)
                            cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), PERSON_COLOR, 2)
                            
                        elif cls_id in DANGER_OBJECT_IDS:
                            # ìœ„í—˜ ë¬¼ê±´ ë°ì´í„° ìˆ˜ì§‘
                            danger_data.append((box, center_x, center_y, conf))
                            # ìœ„í—˜ ë¬¼ê±´ ë°•ìŠ¤ ê·¸ë¦¬ê¸° (ë¹¨ê°„ìƒ‰)
                            cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), DANGER_COLOR, 3)
                            label = CLASS_NAMES.get(cls_id, 'Danger')
                            # ì‹ ë¢°ë„ ì ìˆ˜ë„ í•¨ê»˜ í‘œì‹œ
                            cv2.putText(annotated_frame, f"{label} ({conf:.2f})", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, DANGER_COLOR, 2)

                    # 4. **[ì•Œê³ ë¦¬ì¦˜ ê°œì„ ] ê·¼ì ‘ ê¸°ë°˜ ìœ„í—˜ ì—°ê´€ ë¶„ì„** (ë¡œì§ ë³µêµ¬)
                    for d_box, d_cx, d_cy, d_conf in danger_data:
                        min_distance = float('inf')
                        closest_person_id = -1
                        closest_person_size = 0

                        for p_box, p_track_id, p_cx, p_cy, p_size in person_data:
                            if p_track_id == -1:
                                continue

                            # ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê³„ì‚°
                            distance = np.sqrt((d_cx - p_cx)**2 + (d_cy - p_cy)**2)
                            
                            if distance < min_distance:
                                min_distance = distance
                                closest_person_id = p_track_id
                                closest_person_size = p_size
                                
                        # **ìœ„í—˜ íŒë³„ ì„ê³„ê°’:** ê°€ì¥ ê°€ê¹Œìš´ ì‚¬ëŒì˜ í¬ê¸°(size)ì˜ 60% ì´ë‚´ì— í‰ê¸°ê°€ ìˆë‹¤ë©´ ì†Œì§€í•œ ê²ƒìœ¼ë¡œ ê°„ì£¼
                        PROXIMITY_THRESHOLD = closest_person_size * 0.6 
                        
                        if closest_person_id != -1 and min_distance < PROXIMITY_THRESHOLD:
                            current_danger_track_ids.add(closest_person_id)


                    # 5. ë©”ëª¨ë¦¬ ì—…ë°ì´íŠ¸ ë° ìµœì¢… ì‹œê°í™” (ë¡œì§ ë³µêµ¬)
                    
                    # ë©”ëª¨ë¦¬ ì—…ë°ì´íŠ¸: ì´ë²ˆ í”„ë ˆì„ì—ì„œ ì†Œì§€ìë¡œ í™•ì¸ëœ ì‚¬ëŒì€ í”„ë ˆì„ ìˆ˜ë¥¼ ìµœëŒ€ë¡œ ì„¤ì •
                    for track_id in current_danger_track_ids:
                        DANGER_MEMORY[track_id] = DANGER_HOLD_FRAMES
                    
                    # ë©”ëª¨ë¦¬ ê°ì†Œ: ì´ë²ˆ í”„ë ˆì„ì—ì„œ ì†Œì§€ìë¡œ í™•ì¸ë˜ì§€ ì•Šì€ ì‚¬ëŒë“¤ì˜ ë©”ëª¨ë¦¬ ê°ì†Œ
                    for track_id in list(DANGER_MEMORY.keys()):
                        if track_id not in current_danger_track_ids and DANGER_MEMORY[track_id] > 0:
                            DANGER_MEMORY[track_id] -= 1
                        
                        # ë©”ëª¨ë¦¬ ë§Œë£Œ ì‹œ í‚¤ ì‚­ì œ
                        if DANGER_MEMORY[track_id] <= 0:
                            del DANGER_MEMORY[track_id]

                    # ìµœì¢… ì‹œê°í™”
                    for p_box, p_track_id, p_cx, p_cy, p_size in person_data:
                        # ë°•ìŠ¤ ì¢Œí‘œë¥¼ ë£¨í”„ ì‹œì‘ ì‹œ ì–¸íŒ©
                        px1, py1, px2, py2 = p_box 
                        
                        is_highlighted_danger = DANGER_MEMORY.get(p_track_id, 0) > 0
                        
                        if is_highlighted_danger:
                            # ì‚¬ëŒ ë°•ìŠ¤ë¥¼ ë¹¨ê°„ìƒ‰ í…Œë‘ë¦¬ë¡œ ë‹¤ì‹œ ê·¸ë ¤ ê°•ì¡°
                            cv2.rectangle(annotated_frame, (px1, py1), (px2, py2), DANGER_COLOR, 4)
                            
                            # í°íŠ¸ ê²½ë¡œ ì˜¤ë¥˜ë¥¼ ëŒ€ë¹„í•˜ì—¬ ì˜ˆì™¸ ì²˜ë¦¬ëœ put_korean_text ì‚¬ìš©
                            annotated_frame = put_korean_text(
                                 annotated_frame, 
                                 f"ID {p_track_id} : í‰ê¸° ì†Œì§€ (ìœ„í—˜)", 
                                 (px1, py1 - 40), 
                                 FONT_PATH, 
                                 FONT_SIZE, 
                                 color=DANGER_COLOR
                             )
                            
                            # 2D í‰ë©´ë„ì— ë¹¨ê°„ìƒ‰ ì ìœ¼ë¡œ í‘œì‹œ
                            # 2D ë§µì— í‘œì‹œí•  ë•Œ ìº¡ì²˜ ì˜ì—­ì— ëŒ€í•œ ìƒëŒ€ ì¢Œí‘œë¥¼ ì‚¬ìš©
                            map_x = int(p_cx / capture_area['width'] * map_width)
                            # ì‚¬ëŒ ë°œë°‘(y2) ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë§µì— í‘œì‹œ
                            map_y = int(py2 / capture_area['height'] * map_height)
                            cv2.circle(current_map, (map_x, map_y), 8, DANGER_COLOR, -1) 

                        else:
                            # ì¼ë°˜ ì‚¬ëŒ ì‹œê°í™” (2D ë§µì— ì¼ë°˜ ì‚¬ëŒ ìœ„ì¹˜ í‘œì‹œ)
                            map_x = int(p_cx / capture_area['width'] * map_width)
                            map_y = int(py2 / capture_area['height'] * map_height)
                            cv2.circle(current_map, (map_x, map_y), 5, PERSON_COLOR, -1) # íŒŒë€ìƒ‰ ì 
                else:
                    # ê°ì§€ ê²°ê³¼ê°€ ì—†ì„ ê²½ìš°, ì›ë³¸ ìº¡ì²˜ í”„ë ˆì„ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                    annotated_frame = frame.copy()


                # ----------------------------------------------------
                # 6. ê²°ê³¼ í™”ë©´ í‘œì‹œ ë° ê²½ê³  ë¬¸êµ¬ ì¶”ê°€
                # ----------------------------------------------------
                
                # ìº¡ì²˜ëœ í™”ë©´ì˜ ë†’ì´ë¥¼ ê°€ì ¸ì™€ì„œ 2D ë§µ í¬ê¸° ì¡°ì •
                target_height = annotated_frame.shape[0]
                resized_current_map = cv2.resize(
                    current_map, 
                    (map_width, target_height), 
                    interpolation=cv2.INTER_LINEAR
                )
                
                # FPS ê³„ì‚°
                end_time = time.time()
                fps = 1 / (end_time - start_time)
                cv2.putText(annotated_frame, f"FPS: {fps:.2f}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)

                # ì „ì²´ ìœ„í—˜ ê°ì§€ í”Œë˜ê·¸ (ë©”ëª¨ë¦¬ì— ìœ„í—˜ ì¸ë¬¼ì´ ë‚¨ì•„ìˆëŠ”ì§€ í™•ì¸)
                overall_danger = len(DANGER_MEMORY) > 0
                
                alert_text = "*********í‰ê¸° ì†Œì§€ ê°ì§€ë¨: ì¦‰ê° ëŒ€ì‘ í•„ìš”**********" if overall_danger else "ìœ„í—˜ ì—†ìŒ"
                text_color = DANGER_COLOR if overall_danger else (0, 255, 0) # ë…¹ìƒ‰ìœ¼ë¡œ ë³€ê²½ (ì•ˆì „)

                annotated_frame = put_korean_text(
                    annotated_frame, 
                    alert_text, 
                    (10, 60), 
                    FONT_PATH, 
                    FONT_SIZE, 
                    color=text_color
                )

                # ë‘ ì´ë¯¸ì§€ ìˆ˜í‰ í•©ì¹˜ê¸°
                combined_display = np.hstack((annotated_frame, resized_current_map))

                cv2.imshow("Crowd Analysis System (Combined)", combined_display)

                # 'q'ë¥¼ ëˆ„ë¥´ë©´ ì¢…ë£Œ
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break

            cv2.destroyAllWindows()
            
    except Exception as e:
        print(f"ì‹œìŠ¤í…œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("mss ëª¨ë“ˆì´ ì ¯ìŠ¨ ì˜¤ë¦° ë‚˜ë…¸ í™˜ê²½ì—ì„œ í™”ë©´ ìº¡ì²˜ ëŒ€ì‹  ì›¹ìº  ì…ë ¥ì„ ì‚¬ìš©í•˜ë„ë¡ ìˆ˜ì •í•´ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    main()